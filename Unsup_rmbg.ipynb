{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage import segmentation\n",
    "from skimage.transform import resize\n",
    "from skimage.segmentation import mark_boundaries # show SLIC result\n",
    "\n",
    "import torch.nn.init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from func.tool import get_fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Unsupervised Segmentation')\n",
    "parser.add_argument('--gpu', default=7, type=int)\n",
    "\n",
    "parser.add_argument('--SAVEDIR', default='model/Unsup_rmbg')\n",
    "parser.add_argument('--XX_DIR', default='data/ori/tesri/')\n",
    "\n",
    "parser.add_argument('--nChannel', metavar='N', default=100, type=int, help='number of channels')\n",
    "parser.add_argument('--maxIter', metavar='T', default=1000, type=int, help='number of maximum iterations')\n",
    "parser.add_argument('--minLabels', default=3, type=int, help='minimum number of labels')\n",
    "parser.add_argument('--lr', metavar='LR', default=0.1, type=float, help='learning rate')\n",
    "parser.add_argument('--nConv', metavar='M', default=2, type=int, help='number of convolutional layers')\n",
    "parser.add_argument('--num_superpixels', metavar='K', default=20000, type=int, help='number of superpixels')\n",
    "parser.add_argument('--compactness', metavar='C', default=100, type=float, help='compactness of superpixels')\n",
    "\n",
    "args = parser.parse_args([]) \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
    "use_cuda =  torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdir = args.XX_DIR\n",
    "moths = os.listdir(imgdir)\n",
    "moths_path = [os.path.join(imgdir, i) for i in moths]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        print(input_dim)\n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_dim, args.nChannel, kernel_size=3, stride=1, padding=1 )\n",
    "        self.bn1 = nn.BatchNorm2d(args.nChannel)\n",
    "        self.conv2 = []\n",
    "        self.bn2 = []\n",
    "        for i in range(args.nConv-1):\n",
    "            self.conv2.append( nn.Conv2d(args.nChannel, args.nChannel, kernel_size=3, stride=1, padding=1 ) )\n",
    "            self.bn2.append( nn.BatchNorm2d(args.nChannel) )\n",
    "        self.conv3 = nn.Conv2d(args.nChannel, args.nChannel, kernel_size=1, stride=1, padding=0 )\n",
    "        self.bn3 = nn.BatchNorm2d(args.nChannel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu( x )\n",
    "        x = self.bn1(x)\n",
    "        for i in range(args.nConv-1):\n",
    "            x = self.conv2[i](x)\n",
    "            x = F.relu( x )\n",
    "            x = self.bn2[i](x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def visul():\n",
    "    im_target_rgb = np.array([label_colours[ c % 100 ] for c in im_target])\n",
    "    im_target_rgb = im_target_rgb.reshape( im.shape ).astype( np.uint8 )\n",
    "    rgb = np.fliplr(im_target_rgb.reshape(-1,3)).reshape(im_target_rgb.shape)\n",
    "    cost = time.time() - s_time\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 20), dpi= 400)\n",
    "    ax = fig.add_subplot(151)\n",
    "    ax.set_title('Input Image\\n{}'.format(fname))\n",
    "    ax.imshow(inpt)\n",
    "\n",
    "    ax = fig.add_subplot(152)\n",
    "    ax.set_title('pred\\n n_label:{} \\n iter:{} \\n time:{}' .format(nLabels,batch_idx+1, cost))\n",
    "    ax.imshow(rgb)\n",
    "\n",
    "    ax = fig.add_subplot(153)\n",
    "\n",
    "    points = [str(rgb[25 ,128, :]), # up-mid\n",
    "              str(rgb[25 ,25, :]),  # up-left\n",
    "              str(rgb[25 ,225,:]),  # up-right\n",
    "              str(rgb[225,25, :]),  # down-left\n",
    "              str(rgb[225,225,:]) ] # down-right \n",
    "    p_max = max(points, key=points.count)\n",
    "    vote =  points.count(p_max)\n",
    "    ax.set_title('keep_center_pixel\\n vote:{}/5' .format(vote))\n",
    "\n",
    "\n",
    "    for pts in ([rgb[25 ,128, :], \n",
    "                 rgb[25 ,25, :], \n",
    "                 rgb[25 ,225,:], \n",
    "                 rgb[225,25, :], \n",
    "                 rgb[225,225,:]]):\n",
    "        if str(pts) == p_max :\n",
    "            rgb_Nto_kp = pts\n",
    "\n",
    "    tmp = rgb.copy()\n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            if np.all(tmp[j,i,:] == rgb_Nto_kp):\n",
    "                tmp[j,i,:] = 1\n",
    "            else:\n",
    "                tmp[j,i,:] = 0\n",
    "\n",
    "    ax.imshow(tmp*255)\n",
    "\n",
    "    ax = fig.add_subplot(154)\n",
    "    tmp2 = rgb.copy()\n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            if np.all(tmp2[j,i,:] == rgb_Nto_kp):\n",
    "                tmp2[j,i,:] = 0\n",
    "            else:\n",
    "                tmp2[j,i,:] = 1\n",
    "    ax.set_title('result')\n",
    "    ax.imshow(tmp2*255)\n",
    "\n",
    "    ax = fig.add_subplot(155)\n",
    "    ax.set_title('result')\n",
    "    ax.imshow(inpt*tmp2 + tmp)\n",
    "\n",
    "    #plt.show()\n",
    "    plt.close() \n",
    "    \n",
    "    save_to_check = os.path.join(model_dir, 'checking')\n",
    "    if not os.path.exists(save_to_check):\n",
    "        os.makedirs(save_to_check)   \n",
    "    fig.savefig(os.path.join(save_to_check, fname+'.png'), dpi=100, format='png',bbox_inches='tight' )\n",
    "    \n",
    "    save_to_rmbg = os.path.join(model_dir, 'moth_rmbg')\n",
    "    if not os.path.exists(save_to_rmbg):\n",
    "        os.makedirs(save_to_rmbg)  \n",
    "    io.imsave(os.path.join(save_to_rmbg, fname+'.png'), inpt*tmp2 + tmp)\n",
    "    \n",
    "    save_to_mask = os.path.join(model_dir, 'moth_rmbg_mask')\n",
    "    if not os.path.exists(save_to_mask):\n",
    "        os.makedirs(save_to_mask)  \n",
    "    io.imsave(os.path.join(save_to_mask, fname+'.png'), tmp2*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erasmia00005\n",
      "SLIC n_LABELS:  16384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nLabels 10 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t06665\n",
      "Erasmia00011\n",
      "SLIC n_LABELS:  16384\n",
      "nLabels 10 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t0017\n",
      "Erasmia00010\n",
      "SLIC n_LABELS:  16384\n",
      "nLabels 10 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t9185\n",
      "Erasmia00009\n",
      "SLIC n_LABELS:  16384\n",
      "nLabels 9 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t4456\n",
      "Erasmia00003\n",
      "SLIC n_LABELS:  16384\n",
      "nLabels 8 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t7113\n",
      "Erasmia00008\n",
      "SLIC n_LABELS:  16384\n",
      "nLabels 8 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t2013\n",
      "Erasmia00004\n",
      "SLIC n_LABELS:  16384\n",
      "nLabels 8 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t6792\n",
      "Erasmia00007\n",
      "SLIC n_LABELS:  16384\n",
      "nLabels 7 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t4847\n",
      "Erasmia00016\n",
      "SLIC n_LABELS:  16384\n",
      "nLabels 7 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t287\n",
      "Erasmia00015\n",
      "SLIC n_LABELS:  16384\n",
      "nLabels 7 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t748\n",
      "Erasmia00013\n",
      "SLIC n_LABELS:  16384\n",
      "nLabels 7 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t5703\n",
      "Erasmia00012\n",
      "SLIC n_LABELS:  16384\n",
      "nLabels 7 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t2748\n",
      "Erasmia00014\n",
      "SLIC n_LABELS:  16384\n",
      "nLabels 7 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t9186\n",
      "Erasmia00006\n",
      "SLIC n_LABELS:  16384\n",
      "nLabels 7 reached minLabels 10 \t\t\t\t\t\t\t\t\t\t3893\n"
     ]
    }
   ],
   "source": [
    "### Save DIR\n",
    "save_dir = '%s/' %(args.SAVEDIR)\n",
    "if not os.path.exists(save_dir):\n",
    "                 os.makedirs(save_dir)\n",
    "### Model naming\n",
    "log_time_str = time.strftime(\"%y%m%d%H%M%S\")\n",
    "model_dir = os.path.join(save_dir, log_time_str)\n",
    "\n",
    "### init & loss, optimizer setting\n",
    "model = MyNet(3)\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    for i in range(args.nConv-1):\n",
    "        model.conv2[i].cuda()\n",
    "        model.bn2[i].cuda()\n",
    "model.train()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n",
    "\n",
    "\n",
    "label_colours = np.random.randint(255,size=(100,3))\n",
    "\n",
    "for img_path in moths_path:\n",
    "    s_time = time.time()\n",
    "    \n",
    "    # input: load and process\n",
    "    im = cv2.imread(img_path)\n",
    "    im = resize(im,(256,256))\n",
    "    fname = get_fname(img_path)\n",
    "    print(fname)\n",
    "    data = torch.from_numpy(np.array([im.transpose((2, 0, 1)).astype('float32')/255.])) #\n",
    "    if use_cuda:\n",
    "        data = data.cuda()\n",
    "    data = Variable(data)\n",
    "    inpt = np.fliplr(im.reshape(-1,3)).reshape(im.shape)\n",
    "    \n",
    "    \n",
    "    ### slic\n",
    "        # The compactness parameter trades off color-similarity and proximity, as in the case of Quickshift,\n",
    "        # while n_segments chooses the number of centers for kmeans.\n",
    "    labels = segmentation.slic(im, compactness=args.compactness, n_segments=args.num_superpixels)\n",
    "#     print('SLIC number of segments: {}'.format(len(np.unique(labels))))\n",
    "#     plt.imshow(mark_boundaries(im, labels))\n",
    "#     plt.show()\n",
    "    labels = labels.reshape(im.shape[0]*im.shape[1]) # flatten\n",
    "    u_labels = np.unique(labels)\n",
    "        # put place_index with same SLIC group in a same sublist\n",
    "        # n_sublist = number of unique labels\n",
    "    l_inds = []    \n",
    "    for i in range(len(u_labels)):\n",
    "        l_inds.append(np.where(labels == u_labels[i])[0])\n",
    "    print('SLIC n_LABELS: ', len(u_labels))\n",
    "        \n",
    "    for batch_idx in range(args.maxIter):\n",
    "        # forwarding\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)[0]\n",
    "        output = output.permute(1, 2, 0).contiguous().view(-1, args.nChannel)\n",
    "        ignore, target = torch.max(output,1)\n",
    "        \n",
    "        im_target = target.data.cpu().numpy()\n",
    "        nLabels = len(np.unique(im_target))\n",
    "#         print('MODEL OUTPUT n_LABELS: ', nLabels)\n",
    "        \n",
    "        visul()\n",
    "        \n",
    "        # superpixel refinement\n",
    "        # TODO: use Torch Variable instead of numpy for faster calculation\n",
    "        for i in range(len(l_inds)):\n",
    "            labels_per_sp = im_target[l_inds[i]]\n",
    "            u_labels_per_sp = np.unique(labels_per_sp)\n",
    "            hist = np.zeros(len(u_labels_per_sp))\n",
    "            for j in range(len(hist)):\n",
    "                hist[j] = len(np.where(labels_per_sp == u_labels_per_sp[j])[0])\n",
    "            im_target[l_inds[i]] = u_labels_per_sp[ np.argmax(hist)]\n",
    "        target = torch.from_numpy(im_target)\n",
    "        if use_cuda:\n",
    "            target = target.cuda()\n",
    "        target = Variable(target)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(batch_idx, '/', args.maxIter, 'n_label:', nLabels, 'loss:',loss.data[0], end='\\r')\n",
    "        if nLabels <= args.minLabels:\n",
    "            print(\"nLabels\", nLabels, \"reached minLabels\", args.minLabels, \"\\t\" * 10)\n",
    "            if not os.path.exists(model_dir):\n",
    "                os.makedirs(model_dir)\n",
    "            torch.save(model.state_dict(), model_dir + '/model.pkl')\n",
    "            \n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE_LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/Unsup_rmbg/training_summary.csv\n"
     ]
    }
   ],
   "source": [
    "### Save log\n",
    "summary_save = '%s/training_summary.csv' %(args.SAVEDIR)\n",
    "# save into dictionary\n",
    "sav = vars(args)\n",
    "sav['model_dir'] = model_dir\n",
    "\n",
    "\n",
    "### Append into summary files\n",
    "dnew = pd.DataFrame(sav, index=[0])\n",
    "if os.path.exists(summary_save):\n",
    "    dori = pd.read_csv(summary_save)\n",
    "    dori = pd.concat([dori, dnew])\n",
    "    dori.to_csv(summary_save, index=False)\n",
    "else:\n",
    "    dnew.to_csv(summary_save, index=False)\n",
    "\n",
    "print(summary_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
